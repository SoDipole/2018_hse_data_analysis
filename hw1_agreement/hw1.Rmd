---
title: "hw1"
author: "Polina Sonina"
date: '20 февраля 2018 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(irr)
```

### 1.1
_Скачайте датасет hw1_1_zilo_class.csv. Получите тиббл содержащий два столбца: stimulus_source и количество уникальных слов в датасете (n)._
```{r}
zilo_classes <- read_csv("https://raw.githubusercontent.com/SoDipole/2018_hse_data_analysis/master/hw1_agreement/hw1_1_zilo_class.csv")
zilo_classes <- as_tibble(zilo_classes)
zilo_classes %>%
  distinct(stimulus_source, translation_ru) %>% 
  count(stimulus_source)
```

### 1.2
_Преобразуйте датасет hw1_1_zilo_class.csv. Посчитайте процент полного согласия всех спикеров._
```{r}
zilo_classes %>% 
  select(s_id, stimulus, translation_ru, stimulus_source, class) %>% 
  spread(key = s_id, value = class) ->
  zilo_classes_short
agree(zilo_classes_short[,-c(1:3)])
```

### 1.3
_Из преобразованным датасета hw1_1_zilo_class.csv выберите спикеров с номером 7 и 11 и посчитайте для них каппу Коэна._
```{r}
zilo_classes_2s <- zilo_classes_short[,c(7, 11)]
kappa2(zilo_classes_2s)
```

### 1.4
_Посчитайте каппу Фляйса для всех спикеров преобразованного датасета hw1_1_zilo_class.csv._
```{r}
kappam.fleiss(zilo_classes_short[,-c(1:3)])
```

### 1.5
_Представим, что Вы пишите статью, напишите короткий абзац, который бы обобщал результаты, полученные в предыдущих заданиях._ 
<br>Процент полного согласия всех спикеров составил 73%. Мера согласованности каппа Коэна равна 0.77, что интерпретируется как значительная согласованность (substantial agreement). Обобщённая каппа Коэна для всех спикеров - каппа Фляйса равна 0.84, что интерпретируется как почти идеальная согласованность (almost perfect agreement).

### 2.1
_Скачайте датасет hw1_2_verbs.csv (см. описание выше). Посчитайте количество участников в датасете (в ответ выведите тибл с переменной n)._
```{r}
marginal_verbs <- read_csv("https://raw.githubusercontent.com/SoDipole/2018_hse_data_analysis/master/hw1_agreement/hw1_2_verbs.csv")
marginal_verbs <- as_tibble(marginal_verbs)
marginal_verbs %>%
  distinct(SubjectCode) %>% 
  summarise(n = n())
```

### 2.2
_Посчитайте среднюю оценку глаголов разного типа для каждого пола в датасете (в ответ выведите тибл с переменными WordType, Gender и mean)._
``` {r}
marginal_verbs %>%
  group_by(WordType, Gender) %>% 
  summarize(mean = mean(GivenScore))
```

### 2.3
_Преобразуйте датасет в короткий формат и удалите строки, в которых есть пропущенные значения (у меня вышел тибл 59 x 124). Посчитайте процент полного согласия._
``` {r}
marginal_verbs %>% 
  select(SubjectCode, Stimulus, WordType, Prefix, GivenScore) %>% 
  spread(key = SubjectCode, value = GivenScore) ->
  marginal_verbs_short
marginal_verbs_short <- drop_na(marginal_verbs_short)
agree(marginal_verbs_short[,-c(1:3)])
```

### 2.4
_Посчитайте каппу Фляйса для преобразованного датасета._
``` {r}
kappam.fleiss(marginal_verbs_short[,-c(1:3)])
```

### 2.4
_Посчитайте ICC для преобразованного датасета._
``` {r}
icc(marginal_verbs_short[,-c(1:3)], model = "twoway", type = "agreement")
```

### 2.5
_Создайте тибл, содержащий минимальное (min) и максимальное (max) значение попарной корреляции Кендала ответов всех участников эксперимента со словами (т. е. корреляция ответов АА и AB, AA и AC и т. д.). В преобразовании матрицы, пораждаемой функцией cor() мне очень помогла функция as.table()._
``` {r}
corr_table <- as.table(cor(marginal_verbs_short[,-c(1:3)], method = "kendall"))
tibble(min = min(corr_table[upper.tri(corr_table)]), max = max(corr_table[upper.tri(corr_table)]))
```








